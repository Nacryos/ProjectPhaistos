{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhoneticPriorModel Training\n",
    "\n",
    "This notebook runs the full paper-style experiments for the PhoneticPriorModel\n",
    "(Luo et al. 2021, TACL) decipherment system.\n",
    "\n",
    "**Experiments:**\n",
    "- **Ugaritic** (Table 3): Ugaritic → Hebrew decipherment, P@1 metric\n",
    "- **Gothic** (Table 2 + 4): Gothic → Proto-Germanic / Old Norse / Old English, P@10 metric\n",
    "- **Iberian Names** (Figure 4a): Iberian personal names → Latin, P@K curves\n",
    "- **Validation branches**: 55 language family branches from ancient-scripts-datasets\n",
    "\n",
    "**Estimated training times** (with batch_size=8, 3 restarts):\n",
    "| Experiment | Runs | Est. Time |\n",
    "|---|---|---|\n",
    "| Ugaritic | 6 (2 variants × 3 restarts) | ~2-3 hours |\n",
    "| Iberian Names | 6 (2 variants × 3 restarts) | ~1-2 hours |\n",
    "| Gothic | 36+ (3 variants × 4 WR × 3 restarts) | ~8-12 hours |\n",
    "\n",
    "**Runtime:** Select **T4 GPU** or **CPU** (the model uses CPU-bound DP loops,\n",
    "so GPU helps marginally with tensor ops but not the core bottleneck)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Clone repo and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone the repository\n",
    "if not os.path.exists('/content/ProjectPhaistos'):\n",
    "    !git clone https://github.com/Nacryos/ProjectPhaistos.git /content/ProjectPhaistos\n",
    "else:\n",
    "    !cd /content/ProjectPhaistos && git pull\n",
    "\n",
    "# Set working directory\n",
    "os.chdir('/content/ProjectPhaistos/repro_decipher_phonetic_prior')\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q panphon pyyaml matplotlib scipy numpy torch\n",
    "\n",
    "# Required for panphon IPA feature extraction\n",
    "os.environ['PYTHONUTF8'] = '1'\n",
    "\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Verify data files and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets.registry import get_corpus, list_corpora\n",
    "\n",
    "# Check core data files exist\n",
    "critical_files = [\n",
    "    'third_party/NeuroDecipher/data/uga-heb.small.no_spe.cog',\n",
    "    'third_party/DecipherUnsegmented/data/iberian.csv',\n",
    "    'data_external/rodriguez_ramos_2014_personal_names.tsv',\n",
    "    'data_external/wiktionary_descendants_pg.tsv',\n",
    "    'data_external/wiktionary_descendants_on.tsv',\n",
    "    'data_external/wiktionary_descendants_oe.tsv',\n",
    "    'configs/gothic.yaml',\n",
    "    'configs/ugaritic.yaml',\n",
    "    'configs/iberian.yaml',\n",
    "    'configs/validation.yaml',\n",
    "]\n",
    "\n",
    "print('Data file check:')\n",
    "all_ok = True\n",
    "for f in critical_files:\n",
    "    exists = Path(f).exists()\n",
    "    status = 'OK' if exists else 'MISSING'\n",
    "    if not exists:\n",
    "        all_ok = False\n",
    "    print(f'  {status}: {f}')\n",
    "\n",
    "# Check corpora load\n",
    "print(f'\\nAvailable corpora: {list_corpora()[:10]}...')\n",
    "\n",
    "# Quick load test\n",
    "for name in ['ugaritic', 'gothic', 'iberian']:\n",
    "    c = get_corpus(name)\n",
    "    print(f'  {name}: {len(c.lost_text)} training texts')\n",
    "\n",
    "# Check imports\n",
    "import torch\n",
    "import panphon\n",
    "print(f'\\nPyTorch: {torch.__version__} (CUDA: {torch.cuda.is_available()})')\n",
    "print(f'panphon: {panphon.__version__}')\n",
    "\n",
    "if all_ok:\n",
    "    print('\\nAll checks passed. Ready to train.')\n",
    "else:\n",
    "    print('\\nSome files missing. Check the output above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Smoke test (quick validation that everything works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Run a quick smoke test on Ugaritic to verify the pipeline\n",
    "print('Running Ugaritic smoke test...')\n",
    "t0 = time.time()\n",
    "!python -m repro.run_experiment ugaritic --smoke --restarts 1 --output-root outputs_smoke\n",
    "print(f'Smoke test completed in {time.time() - t0:.1f}s')\n",
    "\n",
    "# Show results\n",
    "import json\n",
    "summary_path = Path('outputs_smoke/ugaritic/run_summary.json')\n",
    "if summary_path.exists():\n",
    "    summary = json.loads(summary_path.read_text())\n",
    "    print(f'\\nSmoke test results:')\n",
    "    for row in summary.get('rows', []):\n",
    "        print(f\"  {row.get('method', '?')}: P@1={row.get('score_best', 0):.3f}\")\n",
    "    print('\\nPipeline is working correctly.')\n",
    "else:\n",
    "    print('Smoke test output not found. Check for errors above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Save results to Google Drive (recommended)\n\nColab sessions are **temporary** — when the session ends, all local files are deleted.\nTo keep your results, save them to Google Drive.\n\n**How to use:** Change `SAVE_TO_DRIVE = False` to `SAVE_TO_DRIVE = True` in the cell below,\nthen run it. A popup will ask you to sign in and grant access — just click through it."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ======================================================\n# CHANGE THIS TO True TO SAVE RESULTS TO GOOGLE DRIVE\nSAVE_TO_DRIVE = False\n# ======================================================\n\nimport os\n\nif SAVE_TO_DRIVE:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    OUTPUT_ROOT = '/content/drive/MyDrive/PhoneticPriorModel/outputs'\n    print('Google Drive mounted. Results will persist across sessions.')\nelse:\n    OUTPUT_ROOT = '/content/ProjectPhaistos/repro_decipher_phonetic_prior/outputs'\n    print('Using local storage. Results will be LOST when this session ends.')\n    print('To keep results, set SAVE_TO_DRIVE = True above and re-run this cell.')\n\nos.makedirs(OUTPUT_ROOT, exist_ok=True)\nprint(f'\\nOutput directory: {OUTPUT_ROOT}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Ugaritic Experiment (Table 3)\n",
    "\n",
    "The primary evaluation from the paper. Deciphers Ugaritic text using Hebrew as the known language.\n",
    "\n",
    "- **Paper baselines**: Bayesian (P@1=0.054), NeuroCipher (P@1=0.654)\n",
    "- **Paper result**: base=0.583, full=0.672\n",
    "- **Variants**: `base` (no prior), `full` (full mapping prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "RESTARTS = 3  # Paper uses 5; reduce for faster initial runs\n",
    "\n",
    "print(f'Starting Ugaritic experiment ({RESTARTS} restarts, ~2-3 hours)...')\n",
    "print(f'Output: {OUTPUT_ROOT}/ugaritic/')\n",
    "t0 = time.time()\n",
    "\n",
    "!python -m repro.run_experiment ugaritic \\\n",
    "    --restarts {RESTARTS} \\\n",
    "    --output-root {OUTPUT_ROOT}\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nUgaritic experiment completed in {elapsed/60:.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Ugaritic results\n",
    "import json, csv\n",
    "from pathlib import Path\n",
    "\n",
    "table3_path = Path(f'{OUTPUT_ROOT}/ugaritic/table3_ugaritic.csv')\n",
    "if table3_path.exists():\n",
    "    print('=== Ugaritic Results (Table 3 style) ===')\n",
    "    print(f'{\"Method\":<20} {\"P@1 Best\":>10} {\"P@1 Mean\":>10} {\"P@1 Std\":>10}')\n",
    "    print('-' * 52)\n",
    "    with table3_path.open() as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            print(f\"{row['method']:<20} {float(row['score_best']):>10.3f} {float(row['score_mean']):>10.3f} {float(row.get('score_std', 0)):>10.3f}\")\n",
    "else:\n",
    "    print('Results not found. Check experiment output above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Iberian Personal Names Experiment (Figure 4a)\n",
    "\n",
    "Evaluates the model on Iberian personal names from the Bronze of Ascoli,\n",
    "compared against Latin cognates.\n",
    "\n",
    "- **Metrics**: P@1, P@3, P@5, P@10 curves\n",
    "- **Variants**: `base` (no prior), `full` (full mapping prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(f'Starting Iberian names experiment ({RESTARTS} restarts, ~1-2 hours)...')\n",
    "print(f'Output: {OUTPUT_ROOT}/iberian_names/')\n",
    "t0 = time.time()\n",
    "\n",
    "!python -m repro.run_experiment iberian-names \\\n",
    "    --restarts {RESTARTS} \\\n",
    "    --output-root {OUTPUT_ROOT}\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nIberian names experiment completed in {elapsed/60:.1f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Iberian P@K results\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "pk_path = Path(f'{OUTPUT_ROOT}/iberian_names/p_at_k.csv')\n",
    "if pk_path.exists():\n",
    "    print('=== Iberian Names P@K Results ===')\n",
    "    print(f'{\"Variant\":<15} {\"K\":>5} {\"P@K Best\":>10} {\"P@K Mean\":>10}')\n",
    "    print('-' * 42)\n",
    "    with pk_path.open() as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            print(f\"{row['variant']:<15} {int(row['k']):>5} {float(row['p_at_k_best']):>10.3f} {float(row['p_at_k_mean']):>10.3f}\")\n",
    "else:\n",
    "    print('Results not found.')\n",
    "\n",
    "# Show the P@K curve plot if generated\n",
    "from IPython.display import Image, display\n",
    "fig_path = Path(f'{OUTPUT_ROOT}/iberian_names/p_at_k_curve.png')\n",
    "if fig_path.exists():\n",
    "    display(Image(filename=str(fig_path), width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Gothic Experiment (Table 2 + 4)\n",
    "\n",
    "The most comprehensive experiment. Tests across 3 known languages (PG, ON, OE),\n",
    "4 whitespace ratios (0%, 25%, 50%, 75%), and 3 model variants.\n",
    "\n",
    "**This is the longest experiment.** Consider:\n",
    "- Reducing variants: `--variants base,full` (skip partial)\n",
    "- Reducing restarts: already using 3 instead of 5\n",
    "- Running overnight on Colab Pro for longer session limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# For faster initial results, run with fewer variants\n",
    "GOTHIC_VARIANTS = 'base,full'  # Skip 'partial' to save time; add it back with 'base,partial,full'\n",
    "\n",
    "print(f'Starting Gothic experiment ({RESTARTS} restarts, variants={GOTHIC_VARIANTS})...')\n",
    "print(f'Output: {OUTPUT_ROOT}/gothic/')\n",
    "print('This will take several hours. Consider running overnight.')\n",
    "t0 = time.time()\n",
    "\n",
    "!python -m repro.run_experiment gothic \\\n",
    "    --restarts {RESTARTS} \\\n",
    "    --variants {GOTHIC_VARIANTS} \\\n",
    "    --output-root {OUTPUT_ROOT}\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nGothic experiment completed in {elapsed/3600:.1f} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Gothic Table 2 results\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "t2_path = Path(f'{OUTPUT_ROOT}/gothic/table2.csv')\n",
    "if t2_path.exists():\n",
    "    print('=== Gothic Results (Table 2 style) ===')\n",
    "    print(f'{\"WR%\":<6} {\"Known\":<8} {\"Base\":>8} {\"Partial\":>8} {\"Full\":>8}')\n",
    "    print('-' * 42)\n",
    "    with t2_path.open() as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            base = f\"{float(row['base']):.3f}\" if row.get('base') else '-'\n",
    "            partial = f\"{float(row['partial']):.3f}\" if row.get('partial') else '-'\n",
    "            full = f\"{float(row['full']):.3f}\" if row.get('full') else '-'\n",
    "            print(f\"{row['whitespace_ratio']:<6} {row['known_language']:<8} {base:>8} {partial:>8} {full:>8}\")\n",
    "else:\n",
    "    print('Results not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Generate visualizations\n",
    "\n",
    "Auto-detect experiment outputs and generate all applicable plots:\n",
    "- Character distribution heatmaps\n",
    "- Training loss curves\n",
    "- P@K curves\n",
    "- Branch comparison bar charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Generate visualizations for each completed experiment\n",
    "for experiment in ['ugaritic', 'gothic', 'iberian_names']:\n",
    "    exp_dir = Path(f'{OUTPUT_ROOT}/{experiment}')\n",
    "    if exp_dir.exists():\n",
    "        print(f'\\nGenerating visualizations for {experiment}...')\n",
    "        !python -m repro.run_experiment visualize {exp_dir}\n",
    "    else:\n",
    "        print(f'Skipping {experiment} (not yet run)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display generated figures\n",
    "from pathlib import Path\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for experiment in ['ugaritic', 'gothic', 'iberian_names']:\n",
    "    fig_dir = Path(f'{OUTPUT_ROOT}/{experiment}/figures')\n",
    "    if fig_dir.exists():\n",
    "        pngs = sorted(fig_dir.glob('*.png'))\n",
    "        if pngs:\n",
    "            print(f'\\n=== {experiment} visualizations ===')\n",
    "            for png in pngs:\n",
    "                print(f'\\n{png.name}:')\n",
    "                display(Image(filename=str(png), width=700))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Validation branch experiments (optional)\n",
    "\n",
    "Run the model against validation language family branches from\n",
    "ancient-scripts-datasets. Each branch tests decipherment within a language\n",
    "family (e.g., Germanic, Semitic, Celtic).\n",
    "\n",
    "These experiments test generalization — how well the phonetic prior\n",
    "works across diverse language families."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available validation branches\n",
    "from datasets.registry import list_corpora\n",
    "\n",
    "val_branches = [c.replace('validation_', '') for c in list_corpora() if c.startswith('validation_')]\n",
    "print(f'Available validation branches ({len(val_branches)}):')\n",
    "for i, b in enumerate(sorted(val_branches)):\n",
    "    print(f'  {i+1:3d}. {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Run a selection of key validation branches\n",
    "# Uncomment or add branches you want to test\n",
    "VALIDATION_BRANCHES = [\n",
    "    'germanic_expanded',\n",
    "    'semitic',\n",
    "    # 'celtic',\n",
    "    # 'romance',\n",
    "    # 'slavic',\n",
    "    # 'turkic',\n",
    "]\n",
    "\n",
    "for branch in VALIDATION_BRANCHES:\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'Running validation: {branch} ({RESTARTS} restarts)...')\n",
    "    t0 = time.time()\n",
    "    !python -m repro.run_experiment validation \\\n",
    "        --branch {branch} \\\n",
    "        --restarts {RESTARTS} \\\n",
    "        --output-root {OUTPUT_ROOT}\n",
    "    print(f'Completed {branch} in {(time.time()-t0)/60:.1f} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Download results\n",
    "\n",
    "Download the full outputs directory as a zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(OUTPUT_ROOT)\n",
    "if output_dir.exists() and any(output_dir.iterdir()):\n",
    "    zip_path = '/content/phaistos_results'\n",
    "    shutil.make_archive(zip_path, 'zip', output_dir)\n",
    "    print(f'Results archived to {zip_path}.zip')\n",
    "    print(f'Size: {Path(zip_path + \".zip\").stat().st_size / 1024 / 1024:.1f} MB')\n",
    "    \n",
    "    # Auto-download in Colab\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        files.download(f'{zip_path}.zip')\n",
    "    except ImportError:\n",
    "        print('Not in Colab. Download the zip manually.')\n",
    "else:\n",
    "    print('No results to download yet.')"
   ]
  }
 ]
}